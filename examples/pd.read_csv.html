<!DOCTYPE html><html lang="en"><head>    <meta charset="UTF-8">    <title>pandas.io.parsers.read_csv</title>    <link rel="stylesheet" href="http://www.52phm.cn/static/bootstrap.min.css">    <script src="http://www.52phm.cn/static/bootstrap.min.js"></script></head><body style="background:#eaeaea"><div class="container body-main">      <div class="col-md-2" role="complementary">             <div class="media" style="background-color:#f5f5f5;width:auto;min-height:350px;color:black;background:#f8f8f8;padding:10px;box-shadow:0px 0px 3px 3px #f0f0f0">                    <p style="text-align:left;line-height:25px;"><a href="#Parameters"><img src="http://www.52phm.cn/media/editor/reply.svg"> Parameters</a></p><br><p style="text-align:left;line-height:25px;"><a href="#Returns"><img src="http://www.52phm.cn/media/editor/reply.svg"> Returns</a></p><br><p style="text-align:left;line-height:25px;"><a href="#See Also"><img src="http://www.52phm.cn/media/editor/reply.svg"> See Also</a></p><br><p style="text-align:left;line-height:25px;"><a href="#Examples"><img src="http://www.52phm.cn/media/editor/reply.svg"> Examples</a></p>            </div>      </div>      <div class="col-md-7" role="main">             <div class="media" style="width:auto; height:auto;color:black;background:#f8f8f8;padding:10px;box-shadow:0px 0px 3px 3px #f0f0f0">                    <h3>pandas.io.parsers.read_csv</h3><br>Help on function read_csv in module pandas.io.parsers<br><br><div style="background-color:#fbe54e">read_csv(filepath_or_buffer:Union[str, pathlib.Path, IO[~AnyStr]], sep=',', delimiter=None, header='infer', names=None, index_col=None, usecols=None, squeeze=False, prefix=None, mangle_dupe_cols=True, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=False, skip_blank_lines=True, parse_dates=False, infer_datetime_format=False, keep_date_col=False, date_parser=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal:str='.', lineterminator=None, quotechar='"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, dialect=None, error_bad_lines=True, warn_bad_lines=True, delim_whitespace=False, low_memory=True, memory_map=False, float_precision=None)<br>    </div><br>Read a comma-separated values (csv) file into DataFrame.<br>    <br>    Also supports optionally iterating or breaking of the file<br>    into chunks.<br>    <br>    Additional help can be found in the online docs for<br>    `IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.<br>    <br><a name="Parameters"></a><h3>Parameters</h3><div style="background-color:#f2eadd;"><div style="margin-left:1.5em;">    filepath_or_buffer : str, path object or file-like object<br>&emsp;&emsp;Any valid string path is acceptable. The string could be a URL. Valid<br>&emsp;&emsp;URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is<br>&emsp;&emsp;expected. A local file could be: file://localhost/path/to/table.csv.<br>    <br>&emsp;&emsp;If you want to pass in a path object, pandas accepts any ``os.PathLike``.<br>    <br>&emsp;&emsp;By file-like object, we refer to objects with a ``read()`` method, such as<br>&emsp;&emsp;a file handler (e.g. via builtin ``open`` function) or ``StringIO``.<br>    sep : str, default ','<br>&emsp;&emsp;Delimiter to use. If sep is None, the C engine cannot automatically detect<br>&emsp;&emsp;the separator, but the Python parsing engine can, meaning the latter will<br>&emsp;&emsp;be used and automatically detect the separator by Python's builtin sniffer<br>&emsp;&emsp;tool, ``csv.Sniffer``. In addition, separators longer than 1 character and<br>&emsp;&emsp;different from ``'\s+'`` will be interpreted as regular expressions and<br>&emsp;&emsp;will also force the use of the Python parsing engine. Note that regex<br>&emsp;&emsp;delimiters are prone to ignoring quoted data. Regex example: ``'\r\t'``.<br>    delimiter : str, default ``None``<br>&emsp;&emsp;Alias for sep.<br>    header : int, list of int, default 'infer'<br>&emsp;&emsp;Row number(s) to use as the column names, and the start of the<br>&emsp;&emsp;data.  Default behavior is to infer the column names: if no names<br>&emsp;&emsp;are passed the behavior is identical to ``header=0`` and column<br>&emsp;&emsp;names are inferred from the first line of the file, if column<br>&emsp;&emsp;names are passed explicitly then the behavior is identical to<br>&emsp;&emsp;``header=None``. Explicitly pass ``header=0`` to be able to<br>&emsp;&emsp;replace existing names. The header can be a list of integers that<br>&emsp;&emsp;specify row locations for a multi-index on the columns<br>&emsp;&emsp;e.g. [0,1,3]. Intervening rows that are not specified will be<br>&emsp;&emsp;skipped (e.g. 2 in this example is skipped). Note that this<br>&emsp;&emsp;parameter ignores commented lines and empty lines if<br>&emsp;&emsp;``skip_blank_lines=True``, so ``header=0`` denotes the first line of<br>&emsp;&emsp;data rather than the first line of the file.<br>    names : array-like, optional<br>&emsp;&emsp;List of column names to use. If the file contains a header row,<br>&emsp;&emsp;then you should explicitly pass ``header=0`` to override the column names.<br>&emsp;&emsp;Duplicates in this list are not allowed.<br>    index_col : int, str, sequence of int / str, or False, default ``None``<br>      Column(s) to use as the row labels of the ``DataFrame``, either given as<br>      string name or column index. If a sequence of int / str is given, a<br>      MultiIndex is used.<br>    <br>      Note: ``index_col=False`` can be used to force pandas to *not* use the first<br>      column as the index, e.g. when you have a malformed file with delimiters at<br>      the end of each line.<br>    usecols : list-like or callable, optional<br>&emsp;&emsp;Return a subset of the columns. If list-like, all elements must either<br>&emsp;&emsp;be positional (i.e. integer indices into the document columns) or strings<br>&emsp;&emsp;that correspond to column names provided either by the user in `names` or<br>&emsp;&emsp;inferred from the document header row(s). For example, a valid list-like<br>&emsp;&emsp;`usecols` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.<br>&emsp;&emsp;Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.<br>&emsp;&emsp;To instantiate a DataFrame from ``data`` with element order preserved use<br>&emsp;&emsp;``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]`` for columns<br>&emsp;&emsp;in ``['foo', 'bar']`` order or<br>&emsp;&emsp;``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``<br>&emsp;&emsp;for ``['bar', 'foo']`` order.<br>    <br>&emsp;&emsp;If callable, the callable function will be evaluated against the column<br>&emsp;&emsp;names, returning names where the callable function evaluates to True. An<br>&emsp;&emsp;example of a valid callable argument would be ``lambda x: x.upper() in<br>&emsp;&emsp;['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster<br>&emsp;&emsp;parsing time and lower memory usage.<br>    squeeze : bool, default False<br>&emsp;&emsp;If the parsed data only contains one column then return a Series.<br>    prefix : str, optional<br>&emsp;&emsp;Prefix to add to column numbers when no header, e.g. 'X' for X0, X1, ...<br>    mangle_dupe_cols : bool, default True<br>&emsp;&emsp;Duplicate columns will be specified as 'X', 'X.1', ...'X.N', rather than<br>&emsp;&emsp;'X'...'X'. Passing in False will cause data to be overwritten if there<br>&emsp;&emsp;are duplicate names in the columns.<br>    dtype : Type name or dict of column -> type, optional<br>&emsp;&emsp;Data type for data or columns. E.g. {'a': np.float64, 'b': np.int32,<br>&emsp;&emsp;'c': 'Int64'}<br>&emsp;&emsp;Use `str` or `object` together with suitable `na_values` settings<br>&emsp;&emsp;to preserve and not interpret dtype.<br>&emsp;&emsp;If converters are specified, they will be applied INSTEAD<br>&emsp;&emsp;of dtype conversion.<br>    engine : {'c', 'python'}, optional<br>&emsp;&emsp;Parser engine to use. The C engine is faster while the python engine is<br>&emsp;&emsp;currently more feature-complete.<br>    converters : dict, optional<br>&emsp;&emsp;Dict of functions for converting values in certain columns. Keys can either<br>&emsp;&emsp;be integers or column labels.<br>    true_values : list, optional<br>&emsp;&emsp;Values to consider as True.<br>    false_values : list, optional<br>&emsp;&emsp;Values to consider as False.<br>    skipinitialspace : bool, default False<br>&emsp;&emsp;Skip spaces after delimiter.<br>    skiprows : list-like, int or callable, optional<br>&emsp;&emsp;Line numbers to skip (0-indexed) or number of lines to skip (int)<br>&emsp;&emsp;at the start of the file.<br>    <br>&emsp;&emsp;If callable, the callable function will be evaluated against the row<br>&emsp;&emsp;indices, returning True if the row should be skipped and False otherwise.<br>&emsp;&emsp;An example of a valid callable argument would be ``lambda x: x in [0, 2]``.<br>    skipfooter : int, default 0<br>&emsp;&emsp;Number of lines at bottom of file to skip (Unsupported with engine='c').<br>    nrows : int, optional<br>&emsp;&emsp;Number of rows of file to read. Useful for reading pieces of large files.<br>    na_values : scalar, str, list-like, or dict, optional<br>&emsp;&emsp;Additional strings to recognize as NA/NaN. If dict passed, specific<br>&emsp;&emsp;per-column NA values.  By default the following values are interpreted as<br>&emsp;&emsp;NaN: '', '#N/A', '#N/A N/A', '#NA', '-1.#IND', '-1.#QNAN', '-NaN', '-nan',<br>&emsp;&emsp;'1.#IND', '1.#QNAN', '<NA>', 'N/A', 'NA', 'NULL', 'NaN', 'n/a',<br>&emsp;&emsp;'nan', 'null'.<br>    keep_default_na : bool, default True<br>&emsp;&emsp;Whether or not to include the default NaN values when parsing the data.<br>&emsp;&emsp;Depending on whether `na_values` is passed in, the behavior is as follows:<br>    <br>&emsp;&emsp;* If `keep_default_na` is True, and `na_values` are specified, `na_values`<br>&emsp;&emsp;  is appended to the default NaN values used for parsing.<br>&emsp;&emsp;* If `keep_default_na` is True, and `na_values` are not specified, only<br>&emsp;&emsp;  the default NaN values are used for parsing.<br>&emsp;&emsp;* If `keep_default_na` is False, and `na_values` are specified, only<br>&emsp;&emsp;  the NaN values specified `na_values` are used for parsing.<br>&emsp;&emsp;* If `keep_default_na` is False, and `na_values` are not specified, no<br>&emsp;&emsp;  strings will be parsed as NaN.<br>    <br>&emsp;&emsp;Note that if `na_filter` is passed in as False, the `keep_default_na` and<br>&emsp;&emsp;`na_values` parameters will be ignored.<br>    na_filter : bool, default True<br>&emsp;&emsp;Detect missing value markers (empty strings and the value of na_values). In<br>&emsp;&emsp;data without any NAs, passing na_filter=False can improve the performance<br>&emsp;&emsp;of reading a large file.<br>    verbose : bool, default False<br>&emsp;&emsp;Indicate number of NA values placed in non-numeric columns.<br>    skip_blank_lines : bool, default True<br>&emsp;&emsp;If True, skip over blank lines rather than interpreting as NaN values.<br>    parse_dates : bool or list of int or names or list of lists or dict, default False<br>&emsp;&emsp;The behavior is as follows:<br>    <br>&emsp;&emsp;* boolean. If True -> try parsing the index.<br>&emsp;&emsp;* list of int or names. e.g. If [1, 2, 3] -> try parsing columns 1, 2, 3<br>&emsp;&emsp;  each as a separate date column.<br>&emsp;&emsp;* list of lists. e.g.  If [[1, 3]] -> combine columns 1 and 3 and parse as<br>&emsp;&emsp;  a single date column.<br>&emsp;&emsp;* dict, e.g. {'foo' : [1, 3]} -> parse columns 1, 3 as date and call<br>&emsp;&emsp;  result 'foo'<br>    <br>&emsp;&emsp;If a column or index cannot be represented as an array of datetimes,<br>&emsp;&emsp;say because of an unparseable value or a mixture of timezones, the column<br>&emsp;&emsp;or index will be returned unaltered as an object data type. For<br>&emsp;&emsp;non-standard datetime parsing, use ``pd.to_datetime`` after<br>&emsp;&emsp;``pd.read_csv``. To parse an index or column with a mixture of timezones,<br>&emsp;&emsp;specify ``date_parser`` to be a partially-applied<br>&emsp;&emsp;:func:`pandas.to_datetime` with ``utc=True``. See<br>&emsp;&emsp;:ref:`io.csv.mixed_timezones` for more.<br>    <br>&emsp;&emsp;Note: A fast-path exists for iso8601-formatted dates.<br>    infer_datetime_format : bool, default False<br>&emsp;&emsp;If True and `parse_dates` is enabled, pandas will attempt to infer the<br>&emsp;&emsp;format of the datetime strings in the columns, and if it can be inferred,<br>&emsp;&emsp;switch to a faster method of parsing them. In some cases this can increase<br>&emsp;&emsp;the parsing speed by 5-10x.<br>    keep_date_col : bool, default False<br>&emsp;&emsp;If True and `parse_dates` specifies combining multiple columns then<br>&emsp;&emsp;keep the original columns.<br>    date_parser : function, optional<br>&emsp;&emsp;Function to use for converting a sequence of string columns to an array of<br>&emsp;&emsp;datetime instances. The default uses ``dateutil.parser.parser`` to do the<br>&emsp;&emsp;conversion. Pandas will try to call `date_parser` in three different ways,<br>&emsp;&emsp;advancing to the next if an exception occurs: 1) Pass one or more arrays<br>&emsp;&emsp;(as defined by `parse_dates`) as arguments; 2) concatenate (row-wise) the<br>&emsp;&emsp;string values from the columns defined by `parse_dates` into a single array<br>&emsp;&emsp;and pass that; and 3) call `date_parser` once for each row using one or<br>&emsp;&emsp;more strings (corresponding to the columns defined by `parse_dates`) as<br>&emsp;&emsp;arguments.<br>    dayfirst : bool, default False<br>&emsp;&emsp;DD/MM format dates, international and European format.<br>    cache_dates : bool, default True<br>&emsp;&emsp;If True, use a cache of unique, converted dates to apply the datetime<br>&emsp;&emsp;conversion. May produce significant speed-up when parsing duplicate<br>&emsp;&emsp;date strings, especially ones with timezone offsets.<br>    <br>&emsp;&emsp;.. versionadded:: 0.25.0<br>    iterator : bool, default False<br>&emsp;&emsp;Return TextFileReader object for iteration or getting chunks with<br>&emsp;&emsp;``get_chunk()``.<br>    chunksize : int, optional<br>&emsp;&emsp;Return TextFileReader object for iteration.<br>&emsp;&emsp;See the `IO Tools docs<br>&emsp;&emsp;<https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_<br>&emsp;&emsp;for more information on ``iterator`` and ``chunksize``.<br>    compression : {'infer', 'gzip', 'bz2', 'zip', 'xz', None}, default 'infer'<br>&emsp;&emsp;For on-the-fly decompression of on-disk data. If 'infer' and<br>&emsp;&emsp;`filepath_or_buffer` is path-like, then detect compression from the<br>&emsp;&emsp;following extensions: '.gz', '.bz2', '.zip', or '.xz' (otherwise no<br>&emsp;&emsp;decompression). If using 'zip', the ZIP file must contain only one data<br>&emsp;&emsp;file to be read in. Set to None for no decompression.<br>    thousands : str, optional<br>&emsp;&emsp;Thousands separator.<br>    decimal : str, default '.'<br>&emsp;&emsp;Character to recognize as decimal point (e.g. use ',' for European data).<br>    lineterminator : str (length 1), optional<br>&emsp;&emsp;Character to break file into lines. Only valid with C parser.<br>    quotechar : str (length 1), optional<br>&emsp;&emsp;The character used to denote the start and end of a quoted item. Quoted<br>&emsp;&emsp;items can include the delimiter and it will be ignored.<br>    quoting : int or csv.QUOTE_* instance, default 0<br>&emsp;&emsp;Control field quoting behavior per ``csv.QUOTE_*`` constants. Use one of<br>&emsp;&emsp;QUOTE_MINIMAL (0), QUOTE_ALL (1), QUOTE_NONNUMERIC (2) or QUOTE_NONE (3).<br>    doublequote : bool, default ``True``<br>       When quotechar is specified and quoting is not ``QUOTE_NONE``, indicate<br>       whether or not to interpret two consecutive quotechar elements INSIDE a<br>       field as a single ``quotechar`` element.<br>    escapechar : str (length 1), optional<br>&emsp;&emsp;One-character string used to escape other characters.<br>    comment : str, optional<br>&emsp;&emsp;Indicates remainder of line should not be parsed. If found at the beginning<br>&emsp;&emsp;of a line, the line will be ignored altogether. This parameter must be a<br>&emsp;&emsp;single character. Like empty lines (as long as ``skip_blank_lines=True``),<br>&emsp;&emsp;fully commented lines are ignored by the parameter `header` but not by<br>&emsp;&emsp;`skiprows`. For example, if ``comment='#'``, parsing<br>&emsp;&emsp;``#empty\na,b,c\n1,2,3`` with ``header=0`` will result in 'a,b,c' being<br>&emsp;&emsp;treated as the header.<br>    encoding : str, optional<br>&emsp;&emsp;Encoding to use for UTF when reading/writing (ex. 'utf-8'). `List of Python<br>&emsp;&emsp;standard encodings<br>&emsp;&emsp;<https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .<br>    dialect : str or csv.Dialect, optional<br>&emsp;&emsp;If provided, this parameter will override values (default or not) for the<br>&emsp;&emsp;following parameters: `delimiter`, `doublequote`, `escapechar`,<br>&emsp;&emsp;`skipinitialspace`, `quotechar`, and `quoting`. If it is necessary to<br>&emsp;&emsp;override values, a ParserWarning will be issued. See csv.Dialect<br>&emsp;&emsp;documentation for more details.<br>    error_bad_lines : bool, default True<br>&emsp;&emsp;Lines with too many fields (e.g. a csv line with too many commas) will by<br>&emsp;&emsp;default cause an exception to be raised, and no DataFrame will be returned.<br>&emsp;&emsp;If False, then these "bad lines" will dropped from the DataFrame that is<br>&emsp;&emsp;returned.<br>    warn_bad_lines : bool, default True<br>&emsp;&emsp;If error_bad_lines is False, and warn_bad_lines is True, a warning for each<br>&emsp;&emsp;"bad line" will be output.<br>    delim_whitespace : bool, default False<br>&emsp;&emsp;Specifies whether or not whitespace (e.g. ``' '`` or ``'    '``) will be<br>&emsp;&emsp;used as the sep. Equivalent to setting ``sep='\s+'``. If this option<br>&emsp;&emsp;is set to True, nothing should be passed in for the ``delimiter``<br>&emsp;&emsp;parameter.<br>    low_memory : bool, default True<br>&emsp;&emsp;Internally process the file in chunks, resulting in lower memory use<br>&emsp;&emsp;while parsing, but possibly mixed type inference.  To ensure no mixed<br>&emsp;&emsp;types either set False, or specify the type with the `dtype` parameter.<br>&emsp;&emsp;Note that the entire file is read into a single DataFrame regardless,<br>&emsp;&emsp;use the `chunksize` or `iterator` parameter to return the data in chunks.<br>&emsp;&emsp;(Only valid with C parser).<br>    memory_map : bool, default False<br>&emsp;&emsp;If a filepath is provided for `filepath_or_buffer`, map the file object<br>&emsp;&emsp;directly onto memory and access the data directly from there. Using this<br>&emsp;&emsp;option can improve performance because there is no longer any I/O overhead.<br>    float_precision : str, optional<br>&emsp;&emsp;Specifies which converter the C engine should use for floating-point<br>&emsp;&emsp;values. The options are `None` for the ordinary converter,<br>&emsp;&emsp;`high` for the high-precision converter, and `round_trip` for the<br>&emsp;&emsp;round-trip converter.<br>    <br><a name="Returns"></a></div></div><h3>Returns</h3><div style="background-color:#f2eadd;"><div style="margin-left:1.5em;">    DataFrame or TextParser<br>&emsp;&emsp;A comma-separated values (csv) file is returned as two-dimensional<br>&emsp;&emsp;data structure with labeled axes.<br>    <br><a name="See Also"></a></div></div><h3>See Also</h3><div style="background-color:#f2eadd;"><div style="margin-left:1.5em;">    DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.<br>    read_csv : Read a comma-separated values (csv) file into DataFrame.<br>    read_fwf : Read a table of fixed-width formatted lines into DataFrame.<br>    <br><a name="Examples"></a></div></div><h3>Examples</h3><div style="background-color:#f2eadd;"><div style="margin-left:1.5em;">    >>> pd.read_csv('data.csv')  # doctest: +SKIP<br><br></div></div><br><br><br>             </div>      </div>      <div class="col-md-3" role="complementary">             <br><p>             </p>      </div></div></body></html>